## AI Virtual Mouse with Hand Gesture Recognition and Voice Assistant
# Overview
This AI Virtual Mouse project leverages hand gesture recognition to control various mouse functions and system settings. Built using MediaPipe, OpenCV, CNN, and Pybind11, it offers an intuitive and hands-free experience for interacting with your computer.

# Features:
Cursor Movement: Control the mouse cursor with hand gestures.
Left Click & Right Click: Perform left and right-click actions through specific hand gestures.
Scrolling: Scroll through content using hand gestures.
Double Click: Execute a double-click with a gesture.
Volume & Brightness Control: Adjust system volume and screen brightness using gestures.
Voice Assistant:Integrated with a voice assistant, the project includes the following capabilities:

Google Search: Perform web searches directly through voice commands.
Find Location on Maps: Quickly find and display locations on Google Maps using voice input.
Current Date and Time: Ask for the current date and time.
Launch & Stop Gesture Recognition: Control the gesture recognition process through voice commands.
Exit Program: End the session with a simple voice command.

Hand Gestures: Use predefined hand gestures to control the mouse and system settings.
Voice Commands: Issue voice commands for additional functionalities like Google search or controlling the gesture recognition.
Technologies Used
MediaPipe: For real-time hand detection and tracking.
OpenCV: For image processing and computer vision tasks.
CNN (Convolutional Neural Network): For gesture recognition.
Pybind11: For seamless integration of C++ and Python in the project.
Contributing
Feel free to submit issues or pull requests. Any contributions are welcome!

License
This project is licensed under the MIT License.
